{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyZk4Pe9JKUTxUnMOlkg8g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FQESRGSaX9ld"},"outputs":[],"source":["ç#drive alanına bağlantı\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/My Drive/hafta8')\n","!pwd"],"metadata":{"id":"uSzl1c2Ra4k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf # yapay sinir ağları kütüphanesi (sklearn yerine)"],"metadata":{"id":"4bl6rvv7a50T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["traindata= pd.read_csv('train.csv') # Veri setinin yüklenmesi"],"metadata":{"id":"5P7qu2x5a7ez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["traindata.head()    # csv dosya içeriği"],"metadata":{"id":"Q_Lpm1KVa9wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Öznitelik Çıkarımı\n","df_cleaned = traindata.drop(['Survived','PassengerId','Name','Ticket','Cabin'],axis=1)\n","X = df_cleaned.iloc[:, :].values  # temizlenmiş veriler pclass, sex,age, sibsp, parch, fare, Embarked\n","y = traindata.iloc[:, 1].values   # Hayatta kalma durumu survived özniteliği"],"metadata":{"id":"s45bqwmAa_br"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X) # X veri seti bağımsız değişkenler\n","print(y) # bağımlı değişken"],"metadata":{"id":"6pJIr_pzbMTE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Kayıp veri Analizi\n","from sklearn.impute import SimpleImputer\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean') # strateji; boşluk nasıl doldurulacak\n","imputer.fit(X[:, 2:3])\n","X[:, 2:3] = imputer.transform(X[:, 2:3])                        # 2. ve 3. sütun sayısal değişkenleri\n","\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')  # kategorikte frekansa bakılır (en çok olan alınır)\n","imputer.fit(X[:, 6].reshape(-1,1))\n","X[:, 6] = imputer.transform(X[:, 6].reshape(-1,1)).reshape(-1,)           # 6. sütun kategorik değişkenleri"],"metadata":{"id":"lKcQCxRdbO-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Kategorik verileri sayısala dönüştürdük (Encoding işlemi)\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder # ikilik sayı sisteminde vektör atanır\n","\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))\n","\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:,4] = le.fit_transform(X[:,4])"],"metadata":{"id":"c5-Nn7rnbb8T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train Test verisi ayırma\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n","# test size; test için ayrılan veri kümesi\n","# random state=0 ile veriler sıralı olarak ayrılır. 1 olsaydı rastgele sırada ayırır."],"metadata":{"id":"l21W2qrAbvid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Öznitelik ölçeklendirme. Test ve train verilerine standardizasyon işlemi (alogoritması) uygulanır.\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test) # x test in içine attık, aynı aralığa getirdik; hata vermemesi için"],"metadata":{"id":"_IsYBdcBbwSc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Yapay Sinir ağı modeli oluşturma\n","import tensorflow as tf\n","\n","ann = tf.keras.models.Sequential()                            # ard arda eklenen veriler için model oluşturma\n","ann.add(tf.keras.layers.Dense(units=10, activation='relu'))   # 10 tane giriş, aktivasyon fonk.: derleme şekli\n","ann.add(tf.keras.layers.Dense(units=10, activation='relu'))\n","ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # sigmoid; lojistik regresyona benzer\n","ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","# optimizer; ağırlıkları belirleme, loss; hata hesaplama, accuracy; başarı hesaplama"],"metadata":{"id":"i--kgTWRb7q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Oluşturulan YSA modelinin Fit and predict edilmesi\n","ann.fit(X_train, y_train, batch_size = 10, epochs = 100) # 100 kez eğitim\n","y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","\n","# her eğitimde optimizer güncelleniyor"],"metadata":{"id":"s0evKoCMcDxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Test verilerine bakarak eğitim sonucunda oluşturulan ve predict işlemi gerçekleştirilen modelin değerlendirilmesi.\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)"],"metadata":{"id":"TCxxv317cG5E"},"execution_count":null,"outputs":[]}]}